#if (!require("pacman")) install.packages("pacman")
#pacman::p_load_gh(    
#    "utf8", 
#    "purrr", 
#    "slam", 
#    "data.table", 
#    "vctrs", 
#    "tibble", 
#    "cli", 
#    "rlang", 
#    "dplyr", 
#    "zoo", 
#    "textshape", 
#    "syuzhet, lexicon",
#    "trinker/lexicon",    
#    "trinker/textclean",
#    "downloader",
#    "dplyr"
#)

#devtools::install_version(
# package = "dplyr",
#   repos   = "http://cran.us.r-project.org")


devtools::install_version(
 package = "downloader",
   repos   = "http://cran.us.r-project.org")

devtools::install_version(
 package = "rscopus",
   repos   = "http://cran.us.r-project.org")


  
#  source(paste0(getwd(),'/r/collectors_get_name.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/collectors_get_name.R")

#  source(paste0(getwd(),'/r/collectors_prepare_dictionary.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/collectors_prepare_dictionary.R")

#  source(paste0(getwd(),'/r/collectors_prepare_dictionary_v2.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/collectors_prepare_dictionary_v2.R")

#  source(paste0(getwd(),'/r/export_data_v2.3.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/export_data_v2.3.R")

# source(paste0(getwd(),'/r/extract_gbif_issue.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/extract_gbif_issue.R")

#  source(paste0(getwd(),'/r/generate_collection_event_key.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/generate_collection_event_key.R")

#  source(paste0(getwd(),'/r/parseGBIF_summary.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/parseGBIF_summary.R")

#  source(paste0(getwd(),'/r/prepare_gbif_occurrence_data.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/prepare_gbif_occurrence_data.R")

#  source(paste0(getwd(),'/r/select_digital_voucher_v2.1.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/select_digital_voucher_v2.2.R")

#  source(paste0(getwd(),'/r/select_gbif_fields.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/select_gbif_fields.R")

#  source(paste0(getwd(),'/r/standardize_scientificName.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/standardize_scientificName.R")

#  source(paste0(getwd(),'/r/wcvp_check_name.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/wcvp_check_name.R")

#  source(paste0(getwd(),'/r/wcvp_check_name_batch.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/wcvp_check_name_batch.R")

#  source(paste0(getwd(),'/r/wcvp_get_data.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/wcvp_get_data.R")

#  source(paste0(getwd(),'/r/wcvp_get_data_v2.1.R'))
source("https://raw.githubusercontent.com/pablopains/parseGBIF/main/R/wcvp_get_data_v2.1.R")

  library(dplyr)

  library(downloader)

  #library('textclean')



family_name <- 'Achatocarpaceae'

path_data <- paste0(getwd(),'/data')
if(!dir.exists(path_data)) {dir.create(path_data)}

path_dataGBIF <- paste0(getwd(),'/dataGBIF')
if(!dir.exists(path_dataGBIF)) {dir.create(path_dataGBIF)}

path_dataGBIF <- paste0(getwd(),'/dataGBIF/',family_name)
if(!dir.exists(path_dataGBIF)) {dir.create(path_dataGBIF)}

path_dataWCVP <- paste0(getwd(),'/dataWCVP')
if(!dir.exists(path_dataWCVP)) {dir.create(path_dataWCVP)}


# to load your own file with GBIF occurrences
occ_file <- 'https://raw.githubusercontent.com/pablopains/parseGBIF/main/dataGBIF/Achatocarpaceae/occurrence.txt'

# to load file with GBIF occurrences example for package execution 
# occ_file <- paste0(path_dataGBIF,'/occurrence.txt')
# if(!file.exists(occ_file))
#{
#    occ_file_zip <- paste0(path_dataGBIF,'/occurrence.zip')
#    utils::unzip(occ_file_zip, exdir = path_dataGBIF)
#}

occ <- prepare_gbif_occurrence_data(gbif_occurrece_file = occ_file, columns = 'standard')
  
NROW(occ)

head(occ)


EnumOccurrenceIssue <- readr::read_csv("https://raw.githubusercontent.com/pablopains/parseGBIF/main/dataRaw/EnumOccurrenceIssue.csv",
                                        locale = readr::locale(encoding = "UTF-8"),
                                        show_col_types = FALSE)
NROW(EnumOccurrenceIssue)

head(EnumOccurrenceIssue)

gbif_issue <- extract_gbif_issue(occ = occ,
                                    enumOccurrenceIssue = EnumOccurrenceIssue)

file.name <- paste0(path_dataGBIF,'/parseGBIF_1_occ_issue.csv')

write.csv(gbif_issue$occ_gbif_issue,
            file.name, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")

names(gbif_issue)

NROW(gbif_issue$occ_gbif_issue)

head(gbif_issue$occ_gbif_issue)

wcvp_names <-  wcvp_get_data_v2.1(read_only_to_memory = FALSE,
                                  load_rda_data = TRUE,
                             path_results = path_dataWCVP)$wcvp_names


NROW(wcvp_names)

head(wcvp_names)


names.checked <- wcvp_check_name_batch(occ = occ, 
                                       wcvp_names =  wcvp_names,
                                       if_author_fails_try_without_combinations = TRUE,
                                       wcvp_selected_fields = 'standard',
                                       silence = TRUE)

NROW(names.checked)

names(names.checked)

file.name <- paste0(path_dataGBIF,'/parseGBIF_2_occ_wcvp_check_name.csv')

write.csv(names.checked$occ_wcvp_check_name,
            file.name, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")

collectorsDictionary.dataset <- collectors_prepare_dictionary_v2(occ = occ,
                                                                           collectorDictionary_file = 'https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary_parseGBIF.csv')
  
file.name <- paste0(path_dataGBIF,'/','parseGBIF_3_collectorsDictionary_dataset.csv')
write.csv(collectorsDictionary.dataset, 
            file.name, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")

NROW(collectorsDictionary.dataset)

head(collectorsDictionary.dataset)


# if you manually check the file parseGBIF_3_collectorsDictionary_dataset.csv, 
# use the parameter collectorDictionary_checked_file to indicate the path and name of the file 
# to use it in the function generate_collection_event_key()

# or use the automatically extracted data, already loaded in memory and return from the previous step,
# in parameter collectorDictionary_checked

collectorsDictionary <- generate_collection_event_key(occ=occ,
                                                        # collectorDictionary_checked_file = file.collectorsDictionary.dataset.checked,
                                                        collectorDictionary_checked = collectorsDictionary.dataset,
                                                        collectorDictionary_file = 'https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary_parseGBIF.csv',
                                                        silence = TRUE)


NROW(collectorsDictionary$occ_collectorsDictionary)

head(collectorsDictionary$occ_collectorsDictionary)

file.name <- paste0(path_dataGBIF,'/parseGBIF_3_occ_collectorsDictionary.csv')
  write.csv(collectorsDictionary$occ_collectorsDictionary, file.name, 
            row.names = FALSE, fileEncoding = "UTF-8", na = "")
  
  
file.name <- paste0(path_dataGBIF,'/parseGBIF_3_summary_collectorsDictionary.csv')
  write.csv(collectorsDictionary$summary, file.name, 
            row.names = FALSE, fileEncoding = "UTF-8", na = "")
  
file.name <- paste0(path_dataGBIF,'/parseGBIF_3_collectorsDictionary_add.csv')
  write.csv(collectorsDictionary$collectorsDictionary_add, file.name, 
            row.names = FALSE, fileEncoding = "UTF-8", na = "")


 
digital_voucher <- select_digital_voucher_v2.2(occ = occ,
                                                        occ_gbif_issue = gbif_issue$occ_gbif_issue,
                                                        occ_wcvp_check_name = names.checked$occ_wcvp_check_name,
                                                        occ_collectorsDictionary = collectorsDictionary$occ_collectorsDictionary,
                                                        silence = FALSE)
NROW(digital_voucher$all_data)
head(digital_voucher$all_data)


file.name <- paste0(path_dataGBIF,'/parseGBIF_4_occ_digital_voucher.csv')
write.csv(digital_voucher$all_data,
            file.name, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")

# names(digital_voucher)

# result <- export_data_v2.3(occ_digital_voucher = digital_voucher$occ_digital_voucher)


results <- export_data_v2.3(occ_digital_voucher_file = '',
                                occ_digital_voucher = digital_voucher$occ_digital_voucher,
                                merge_unusable_data = TRUE,
                                silence = FALSE)


names(results)

file.name <-  file.name <- paste0(path_dataGBIF,'/parseGBIF_5_occ_all_data.csv')
write.csv(results$all_data,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")
    
        
file.name <- paste0(path_dataGBIF,'/parseGBIF_5_occ_useable_data_merge.csv')
write.csv(results$useable_data_merge,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")
    
    
file.name <-  paste0(path_dataGBIF,'/parseGBIF_5_occ_useable_data_raw.csv')
write.csv(results$useable_data_raw,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")
    
    
file.name <-  paste0(path_dataGBIF,'/parseGBIF_5_occ_duplicates.csv')
write.csv(results$duplicates,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")
    
    
file.name <-  paste0(path_dataGBIF,'/parseGBIF_5_occ_unusable_data_merge.csv')
write.csv(results$unusable_data_merge,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")
    
file.name <-  paste0(path_dataGBIF,'/parseGBIF_5_occ_unusable_data_raw.csv')
write.csv(results$unusable_data_raw,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")

summ <- parseGBIF_summary(parseGBIF_all_data = results$all_data)

names(summ)

file.name <-  file.name <- paste0(path_dataGBIF,'/parseGBIF_6_general_summary.csv')
write.csv(summ$parseGBIF_general_summary,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")

file.name <-  file.name <- paste0(path_dataGBIF,'/parseGBIF_6_merge_fields_summary.csv')
write.csv(summ$parseGBIF_merge_fields_summary,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")

file.name <-  file.name <- paste0(path_dataGBIF,'/parseGBIF_6_merge_fields_summary_useable_data.csv')
write.csv(summ$parseGBIF_merge_fields_summary_useable_data,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")

file.name <-  file.name <- paste0(path_dataGBIF,'/parseGBIF_6_merge_fields_summary_unusable_data.csv')
write.csv(summ$parseGBIF_merge_fields_summary_unusable_data,
              file.name, 
              row.names = FALSE, 
              fileEncoding = "UTF-8", 
              na = "")



