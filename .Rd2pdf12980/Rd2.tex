\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8]{inputenc} % @SET ENCODING@
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `parseGBIF'}}
\par\bigskip{\large \today}
\end{center}
\inputencoding{utf8}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {parseGBIF: An R package for parsing species occurrence records}}}{}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdfauthor = {Pablo Melo; Nadia Bystriakova; Alexandre Monro}}}{}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{An R package for parsing species occurrence records}
\item[Version]\AsIs{2.0.0}
\item[Date]\AsIs{2023-06-04}
\item[Maintainer]\AsIs{Pablo Melo }\email{pablopains@yahoo.com.br}\AsIs{}
\item[Description]\AsIs{parseGBIF package is designed to convert GBIF species occurrence data to a more comprehensible format to be used for further analysis, e.g. spatial. 
The package provides tools for verifying and standardizing species scientific names and for selecting the most informative species records when duplicates are available. }
\item[License]\AsIs{GPL (>= 2) | file LICENSE}
\item[Encoding]\AsIs{UTF-8}
\item[LazyData]\AsIs{true}
\item[LazyDataCompression]\AsIs{xz}
\item[Roxygen]\AsIs{list(markdown = TRUE)}
\item[RoxygenNote]\AsIs{7.2.3}
\item[Imports]\AsIs{plyr,
readxl,
dplyr,
tidyr,
readr,
stringr,
textclean,
googledrive,
rvest,
lubridate,
rnaturalearthdata,
jsonlite,
sqldf,
DT,
downloader,
tidyselect,
utils}
\item[Remotes]\AsIs{github::pablopains/parseGBIF}
\item[Depends]\AsIs{R (>= 3.5.0)}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{collectors\_get\_name}{Get the last name of the main collector}{collectors.Rul.get.Rul.name}
%
\begin{Description}
Get the last name of the main collector in recordedBy field
\end{Description}
%
\begin{Usage}
\begin{verbatim}
collectors_get_name(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] recordedBy field
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Returns the last name
\end{Details}
%
\begin{Value}
last name of the main collector
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{collectors\_prepare\_dictionary}{collectors.Rul.prepare.Rul.dictionary}}, \code{\LinkA{collectors\_update\_dictionary}{collectors.Rul.update.Rul.dictionary}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(collectors_get_name)

collectors_get_name('Melo, P.H.A & Monro, A.')

collectors_get_name('Monro, A. & Melo, P.H.A')


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{collectors\_prepare\_dictionary}{Prepare the list with the last name of the main collector}{collectors.Rul.prepare.Rul.dictionary}
%
\begin{Description}
Returns the list with the last name of the main collector associated with the unique key recordedBy.
A necessary step for parsing duplicate records is generating a robust key for each unique collecting event
(aka ‘gathering’) that will support the recognition of duplicate records. For this purpose we generate a string
combining the plant family name +  first collector’s surname +  the collection number.
It is therefore essential to consistently record the collector surname and for this purpose we provide a collector
dictionary. To extract the surname of the main collector based on the recordedBy field and assemble a list relating
the last name of the main collector and the raw data from the recordedBy, use the collectors\_prepare\_dictionary function.

It is recommended to check the main collector’s last name in the nameRecordedBy\_Standard field.
Our goal is to standardize the main collector’s last name, which is automatically extracted from the recordedBy field.
We do so by standardizing the text string so that it begins with an uppercase character and to replace non-ascii
characters, so that collector reponsible for a collection event is always recorded using  the same string of characters.
If the searched recordedBy entry is present in the collector’s dictionary, the function retrieves the last name
of the main collector with reference to the recordedBy field (in which case the CollectorDictionary field will be
flagged as ‘checked’), otherwise, the function will return the last name of the main collector, extracted
automatically from the recordedBy field .

Once verified, the collector’s dictionary can be reused in the future.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
collectors_prepare_dictionary(
  occ = NA,
  collectorDictionary_file =
    "https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv",
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{collectorDictionary\_file}] Collector dictionary file - point to a file on your local disk or upload via git at https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv.

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
If recordedBy is present in the collector's dictionary, it returns the checked name, if not, it returns the last name of the main collector, extracted from the recordedBy field.
If recordedBy is present in the collector's dictionary, returns the main collector's last name associated with the single recordedBy key,
otherwise, returns the main collector's last name, extracted from the recordedBy field.
It is recommended to curate the main collector's surname, automatically extracted from the recordedBy field.
The objective is to standardize the last name of the main collector.
That the primary botanical collector of a sample is always recognized by the same last name, standardized in capital letters and non-ascii characters replaced
\end{Details}
%
\begin{Value}
Ctrl\_nameRecordedBy\_Standard,
Ctrl\_recordedBy,
Ctrl\_notes,
collectorDictionary,
Ctrl\_update,
collectorName,
Ctrl\_fullName,
Ctrl\_fullNameII,
CVStarrVirtualHerbarium\_PersonDetails
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{collectors\_get\_name}{collectors.Rul.get.Rul.name}}, \code{\LinkA{generate\_collection\_event\_key}{generate.Rul.collection.Rul.event.Rul.key}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(collectors_prepare_dictionary)

occ <- prepare_gbif_occurrence_data(gbif_occurrece_file =  'https://raw.githubusercontent.com/pablopains/parseGBIF/main/dataGBIF/Achatocarpaceae/occurrence.txt',
                                    columns = 'standard')

collectorsDictionaryFromDataset <- collectors_prepare_dictionary(occ = occ,
                                                                collectorDictionary_file =  'https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv')

colnames(collectorsDictionaryFromDataset)
head(collectorsDictionaryFromDataset)

collectorDictionary_checked_file <- paste0(tempdir(),'/','collectorsDictionaryFromDataset.csv')

collectorDictionary_checked_file

write.csv(collectorsDictionaryFromDataset,
          collectorDictionary_checked_file,
          row.names = FALSE,
          fileEncoding = "UTF-8",
          na = "")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{collectors\_prepare\_dictionary\_v2}{Prepare the list with the last name of the main collector}{collectors.Rul.prepare.Rul.dictionary.Rul.v2}
%
\begin{Description}
Returns the list with the last name of the main collector associated with the unique key recordedBy.
A necessary step for parsing duplicate records is generating a robust key for each unique collecting event
(aka ‘gathering’) that will support the recognition of duplicate records. For this purpose we generate a string
combining the plant family name +  first collector’s surname +  the collection number.
It is therefore essential to consistently record the collector surname and for this purpose we provide a collector
dictionary. To extract the surname of the main collector based on the recordedBy field and assemble a list relating
the last name of the main collector and the raw data from the recordedBy, use the collectors\_prepare\_dictionary function.

It is recommended to check the main collector’s last name in the nameRecordedBy\_Standard field.
Our goal is to standardize the main collector’s last name, which is automatically extracted from the recordedBy field.
We do so by standardizing the text string so that it begins with an uppercase character and to replace non-ascii
characters, so that collector reponsible for a collection event is always recorded using  the same string of characters.
If the searched recordedBy entry is present in the collector’s dictionary, the function retrieves the last name
of the main collector with reference to the recordedBy field (in which case the CollectorDictionary field will be
flagged as ‘checked’), otherwise, the function will return the last name of the main collector, extracted
automatically from the recordedBy field .

Once verified, the collector’s dictionary can be reused in the future.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
collectors_prepare_dictionary_v2(
  occ = NA,
  collectorDictionary_file =
    "https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv",
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{collectorDictionary\_file}] Collector dictionary file - point to a file on your local disk or download via git at https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv.

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
If recordedBy is present in the collector's dictionary, it returns the checked name, if not, it returns the last name of the main collector, extracted from the recordedBy field.
If recordedBy is present in the collector's dictionary, returns the main collector's last name associated with the single recordedBy key,
otherwise, returns the main collector's last name, extracted from the recordedBy field.
It is recommended to curate the main collector's surname, automatically extracted from the recordedBy field.
The objective is to standardize the last name of the main collector.
That the primary botanical collector of a sample is always recognized by the same last name, standardized in capital letters and non-ascii characters replaced
\end{Details}
%
\begin{Value}
Ctrl\_nameRecordedBy\_Standard,
Ctrl\_recordedBy,
Ctrl\_notes,
collectorDictionary,
Ctrl\_update,
collectorName,
Ctrl\_fullName,
Ctrl\_fullNameII,
CVStarrVirtualHerbarium\_PersonDetails
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{collectors\_get\_name}{collectors.Rul.get.Rul.name}}, \code{\LinkA{generate\_collection\_event\_key}{generate.Rul.collection.Rul.event.Rul.key}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(collectors_prepare_dictionary)

occ <- prepare_gbif_occurrence_data(gbif_occurrece_file =  'https://raw.githubusercontent.com/pablopains/parseGBIF/main/dataGBIF/Achatocarpaceae/occurrence.txt',
                                    columns = 'standard')

collectorsDictionaryFromDataset <- collectors_prepare_dictionary(occ = occ,
                                                                collectorDictionary_file =  'https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv')

colnames(collectorsDictionaryFromDataset)
head(collectorsDictionaryFromDataset)

collectorDictionary_checked_file <- paste0(tempdir(),'/','collectorsDictionaryFromDataset.csv')

collectorDictionary_checked_file

write.csv(collectorsDictionaryFromDataset,
          collectorDictionary_checked_file,
          row.names = FALSE,
          fileEncoding = "UTF-8",
          na = "")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{download\_gbif\_data\_from\_doi}{Download GBIF occurrence data from DOI}{download.Rul.gbif.Rul.data.Rul.from.Rul.doi}
%
\begin{Description}
Download and unzip GBIF occurrence data from DOI to be used by ParsGBIF functions
\end{Description}
%
\begin{Usage}
\begin{verbatim}
download_gbif_data_from_doi(
  gbif_doi_url,
  folder = "",
  keep_only_occurrence_file = TRUE,
  overwrite = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{gbif\_doi\_url}] The url of the GBIF DOI

\item[\code{folder}] Save folder

\item[\code{keep\_only\_occurrence\_file}] Keep only occurrence.txt file

\item[\code{overwrite}] overwrite files

\item[\code{subfolder}] Save in subfolder
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Download GBIF occurrence data downloaded from DOI
\end{Details}
%
\begin{Value}
list of downloaded and unzipped files
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{prepare\_gbif\_occurrence\_data}{prepare.Rul.gbif.Rul.occurrence.Rul.data}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}


library(ParsGBIF)

help(download_gbif_data_from_doi)

download_gbif_data_from_doi(gbif_doi_url='https://www.gbif.org/occurrence/download/0151470-230224095556074',
                            folder = 'c://dataGBIF//Achatocarpaceae')


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{EnumOccurrenceIssue}{Enumeration GBIF issue An enumeration of validation rules for single occurrence records.}{EnumOccurrenceIssue}
\keyword{datasets}{EnumOccurrenceIssue}
%
\begin{Description}
There are many things that can go wrong and we continously encounter unexpected data.
In order to help us and publishers improve the data, we flag records with various issues
that we have encountered. This is also very useful for data consumers as you can include
these issues as filters in occurrence searches. Not all issues indicate bad data.
Some are merley flagging the fact that GBIF has altered values during processing.
On the details page of any occurrence record you will see the list of issues in the notice at the bottom.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
data(EnumOccurrenceIssue)
\end{verbatim}
\end{Usage}
%
\begin{Format}
A data frame with 69 rows and 9 columns
\end{Format}
%
\begin{Details}
\begin{description}

\item[constant] GBIF issue constant
\item[description] GBIF issue description
\item[definition] Our definition for classifying geographic issues
\item[type] Type issue
\item[priority] Impact of the issue for the use of geospatial information
\item[score] Impact, in number, of the issue for the use of geospatial information
\item[selection\_score] Value used to calculate the quality of the geospatial information according to the classification of the issue
\item[reasoning] Reasoning of the impact of the theme for the use of geospatial information
\item[notes] Notes

\end{description}

\end{Details}
%
\begin{Source}
\begin{itemize}

\item{} \Rhref{https://www.gbif.org/article/5i3CQEZ6DuWiycgMaaakCo/gbif-infrastructure-data-processing}{GBIF Infrastructure: Data processing}
\item{} \Rhref{https://gbif.github.io/gbif-api/apidocs/org/gbif/api/vocabulary/OccurrenceIssue.html}{An enumeration of validation rules for single occurrence records}

\end{itemize}

\end{Source}
\inputencoding{utf8}
\HeaderA{export\_data}{Export of results}{export.Rul.data}
%
\begin{Description}
For each unique collection event key, complete or incomplete,
outputs will be created which combine information from duplicate records and generate a
single unique collection event record to replace them.
The main output fields relating to taxonomic identification and geographic coordinates:
\begin{itemize}

\item{} parseGBIF\_sample\_taxon\_name = scientific name chosen as taxonomic identification for unique collection event
\item{} parseGBIF\_number\_taxon\_names = number of scientific names found in duplicates of unique collection event
\item{} parseGBIF\_sample\_taxon\_name\_status = status of choice of 'identified', 'divergent identifications', 'unidentified'
\item{} parseGBIF\_unidentified\_sample = if unique collection event has taxonomic identification
\item{} parseGBIF\_decimalLatitude = latitude in decimal degrees
\item{} parseGBIF\_decimalLongitude = longitude in decimal degrees
\item{} parseGBIF\_useful\_for\_spatial\_analysis = whether the coordinates are useful for spatial analysis.
\strong{How is the taxon binomial attributed to the unique collection event selected?}

\end{itemize}

\begin{enumerate}

\item{} Where the unique collection event key is complete:
The accepted TAXON\_NAME selected is that which is most frequently applied to the duplicate vouchers at or below the rank of species.
Where two named are applied with equal frequency then a mechanical approach, using alphabetical order, is applied, the first listed TAXON\_NAME being chosen.
Where there is no identification, at or below the rank of species, then the unique collection event, the unique collection event is indicated as unidentified.
\item{} Where the unique collection event key is incomplete:
Where the unique collection event key is incomplete, then each record is treated as a unique collection event. If there is no identification, at or below the rank of species, then the unique collection event is classified as unidentified.
\_\_Geospatial information \_\_
If the master voucher does not have geographic coordinates, we will seek coordinates from the duplicate records associated with it.
Finally, the records are separated into three sets of data:
\strong{useable\_data} - Where unique collection event with taxonomic identification and geographic coordinates are complete. This represents the useable dataset.
\strong{unusable\_data}  - Where unique collection event without taxonomic identification and/or geographic coordinates.
\strong{duplicates} The duplicates of unique collection events complete / incomplete

\end{enumerate}


With this, it is possible to perform:
Merge information between fields of duplicates of a unique collection event to create a synthetic record for each unique collection event,
Compare the frequency of content in fields
Generate a work package summary

For each complete unique collection event key, data fields that are empty in the digital voucher record will be populated with data from the respective duplicates.
During content merging, we indicate fields associated with the description, location, and data of the unique collection event.
By default, fields\_to\_merge parameter of export\_data function contains:
\begin{itemize}

\item{} Ctrl\_fieldNotes
\item{} Ctrl\_year
\item{} Ctrl\_stateProvince
\item{} Ctrl\_municipality
\item{} Ctrl\_locality
\item{} Ctrl\_countryCode
\item{} Ctrl\_eventDate
\item{} Ctrl\_habitat
\item{} Ctrl\_level0Name
\item{} Ctrl\_level1Name
\item{} Ctrl\_level2Name
\item{} Ctrl\_level3Name

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
export_data(
  occ_digital_voucher_file = "",
  occ_digital_voucher = NA,
  merge_unusable_data = FALSE,
  fields_to_merge = c("Ctrl_fieldNotes", "Ctrl_year", "Ctrl_stateProvince",
    "Ctrl_municipality", "Ctrl_locality", "Ctrl_countryCode", "Ctrl_eventDate",
    "Ctrl_habitat", "Ctrl_level0Name", "Ctrl_level1Name", "Ctrl_level2Name",
    "Ctrl_level3Name"),
  fields_to_compare = c("Ctrl_gbifID", "Ctrl_scientificName", "Ctrl_recordedBy",
    "Ctrl_recordNumber", "Ctrl_identifiedBy", "Ctrl_dateIdentified",
    "Ctrl_institutionCode", "Ctrl_collectionCode", "Ctrl_datasetName",
    "Ctrl_datasetName", "Ctrl_language", "wcvp_plant_name_id", "wcvp_taxon_rank",
    "wcvp_taxon_status", "wcvp_family", "wcvp_taxon_name", "wcvp_taxon_authors",
    "wcvp_reviewed", "wcvp_searchNotes"),
  fields_to_parse = c("Ctrl_gbifID", "Ctrl_bibliographicCitation", "Ctrl_language",
    "Ctrl_institutionCode", "Ctrl_collectionCode", "Ctrl_datasetName",
    "Ctrl_basisOfRecord", "Ctrl_catalogNumber", "Ctrl_recordNumber", "Ctrl_recordedBy",
    "Ctrl_occurrenceStatus", "Ctrl_eventDate", "Ctrl_year", "Ctrl_month", "Ctrl_day",
    "Ctrl_habitat", "Ctrl_fieldNotes", "Ctrl_eventRemarks", "Ctrl_countryCode",
    "Ctrl_stateProvince", "Ctrl_municipality", "Ctrl_county", "Ctrl_locality",
    "Ctrl_level0Name", "Ctrl_level1Name", "Ctrl_level2Name", 
     "Ctrl_level3Name",
    "Ctrl_identifiedBy", "Ctrl_dateIdentified", "Ctrl_scientificName",
    "Ctrl_decimalLatitude", "Ctrl_decimalLongitude", "Ctrl_nameRecordedBy_Standard",
    "Ctrl_recordNumber_Standard", "Ctrl_key_family_recordedBy_recordNumber",
    "Ctrl_geospatial_quality", "Ctrl_verbatim_quality", "Ctrl_moreInformativeRecord",
    "Ctrl_coordinates_validated_by_gbif_issue", "wcvp_plant_name_id", "wcvp_taxon_rank",
    "wcvp_taxon_status", "wcvp_family", "wcvp_taxon_name", "wcvp_taxon_authors",
    "wcvp_reviewed", 
     "wcvp_searchNotes", "parseGBIF_digital_voucher",
    "parseGBIF_duplicates", "parseGBIF_num_duplicates",
    "parseGBIF_non_groupable_duplicates", "parseGBIF_duplicates_grouping_status"),
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ\_digital\_voucher\_file}] CSV fila result of function select\_digital\_voucher()\$occ\_digital\_voucher

\item[\code{occ\_digital\_voucher}] data frame result of function select\_digital\_voucher()\$occ\_digital\_voucher

\item[\code{merge\_unusable\_data}] include records unique collection events incomplete in merge processing

\item[\code{fields\_to\_merge}] fields to merge

\item[\code{fields\_to\_compare}] fields to compare content frequency

\item[\code{fields\_to\_parse}] all fields

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Each data frame should be used as needed
\end{Details}
%
\begin{Value}
list with 10 data frames
\begin{itemize}

\item{} \strong{all\_data} All records processed, merged Unique collection events complete / incomplete and their duplicates
\item{} \strong{useable\_data\_merge} Merged Unique collection events complete
\item{} \strong{useable\_data\_raw} Raw Unique collection events complete
\item{} \strong{duplicates} Duplicates of unique collection events complete / incomplete
\item{} \strong{unusable\_data\_merge} Merged Unique collection events incomplete,
It is NA if merge\_unusable\_data is FALSE.
\item{} \strong{unusable\_data\_raw} Raw Unique collection events incomplete
\item{} \strong{parseGBIF\_general\_summary}
\item{} \strong{parseGBIF\_merge\_fields\_summary}
\item{} \strong{parseGBIF\_merge\_fields\_summary\_useable\_data}
\item{} \strong{parseGBIF\_merge\_fields\_summary\_unusable\_data} It is NA if merge\_unusable\_data is FALSE

\end{itemize}

\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{batch\_checkName\_wcvp}{batch.Rul.checkName.Rul.wcvp}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(export_data)

results <- export_data(occ_digital_voucher_file = file.occ_digital_voucher,
                       merge_unusable_data = TRUE)

names(results)

results$parseGBIF_general_summary
results$parseGBIF_merge_fields_summary
results$parseGBIF_merge_fields_summary_complete
NROW(results$all_data)
NROW(results$unique_collection_event_complete_merge)
NROW(results$unique_collection_event_incomplete_raw)
NROW(results$duplicates)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{export\_data\_v2.3}{Export of results}{export.Rul.data.Rul.v2.3}
%
\begin{Description}
For each unique collection event key, complete or incomplete,
outputs will be created which combine information from duplicate records and generate a
single unique collection event record to replace them.
The main output fields relating to taxonomic identification and geographic coordinates:
\begin{itemize}

\item{} parseGBIF\_sample\_taxon\_name = scientific name chosen as taxonomic identification for unique collection event
\item{} parseGBIF\_number\_taxon\_names = number of scientific names found in duplicates of unique collection event
\item{} parseGBIF\_sample\_taxon\_name\_status = status of choice of 'identified', 'divergent identifications', 'unidentified'
\item{} parseGBIF\_unidentified\_sample = if unique collection event has taxonomic identification
\item{} parseGBIF\_decimalLatitude = latitude in decimal degrees
\item{} parseGBIF\_decimalLongitude = longitude in decimal degrees
\item{} parseGBIF\_useful\_for\_spatial\_analysis = whether the coordinates are useful for spatial analysis.
\strong{How is the taxon binomial attributed to the unique collection event selected?}

\end{itemize}

\begin{enumerate}

\item{} Where the unique collection event key is complete:
The accepted TAXON\_NAME selected is that which is most frequently applied to the duplicate vouchers at or below the rank of species.
Where two named are applied with equal frequency then a mechanical approach, using alphabetical order, is applied, the first listed TAXON\_NAME being chosen.
Where there is no identification, at or below the rank of species, then the unique collection event, the unique collection event is indicated as unidentified.
\item{} Where the unique collection event key is incomplete:
Where the unique collection event key is incomplete, then each record is treated as a unique collection event. If there is no identification, at or below the rank of species, then the unique collection event is classified as unidentified.
\_\_Geospatial information \_\_
If the master voucher does not have geographic coordinates, we will seek coordinates from the duplicate records associated with it.
Finally, the records are separated into three sets of data:
\strong{useable\_data} - Where unique collection event with taxonomic identification and geographic coordinates are complete. This represents the useable dataset.
\strong{unusable\_data}  - Where unique collection event without taxonomic identification and/or geographic coordinates.
\strong{duplicates} The duplicates of unique collection events complete / incomplete

\end{enumerate}


With this, it is possible to perform:
Merge information between fields of duplicates of a unique collection event to create a synthetic record for each unique collection event,
Compare the frequency of content in fields
Generate a work package summary

For each complete unique collection event key, data fields that are empty in the digital voucher record will be populated with data from the respective duplicates.
During content merging, we indicate fields associated with the description, location, and data of the unique collection event.
By default, fields\_to\_merge parameter of export\_data function contains:
\begin{itemize}

\item{} Ctrl\_fieldNotes
\item{} Ctrl\_year
\item{} Ctrl\_stateProvince
\item{} Ctrl\_municipality
\item{} Ctrl\_locality
\item{} Ctrl\_countryCode
\item{} Ctrl\_eventDate
\item{} Ctrl\_habitat
\item{} Ctrl\_level0Name
\item{} Ctrl\_level1Name
\item{} Ctrl\_level2Name
\item{} Ctrl\_level3Name

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
export_data_v2.3(
  occ_digital_voucher_file = "",
  occ_digital_voucher = NA,
  merge_unusable_data = FALSE,
  fields_to_merge = c("Ctrl_fieldNotes", "Ctrl_year", "Ctrl_stateProvince",
    "Ctrl_municipality", "Ctrl_locality", "Ctrl_countryCode", "Ctrl_eventDate",
    "Ctrl_habitat", "Ctrl_level0Name", "Ctrl_level1Name", "Ctrl_level2Name",
    "Ctrl_level3Name"),
  fields_to_compare = c("Ctrl_gbifID", "Ctrl_scientificName", "Ctrl_recordedBy",
    "Ctrl_recordNumber", "Ctrl_identifiedBy", "Ctrl_dateIdentified",
    "Ctrl_institutionCode", "Ctrl_collectionCode", "Ctrl_datasetName",
    "Ctrl_datasetName", "Ctrl_language", "wcvp_plant_name_id", "wcvp_taxon_rank",
    "wcvp_taxon_status", "wcvp_family", "wcvp_taxon_name", "wcvp_taxon_authors",
    "wcvp_reviewed", "wcvp_searchNotes"),
  fields_to_parse = c("Ctrl_gbifID", "Ctrl_bibliographicCitation", "Ctrl_language",
    "Ctrl_institutionCode", "Ctrl_collectionCode", "Ctrl_datasetName",
    "Ctrl_basisOfRecord", "Ctrl_catalogNumber", "Ctrl_recordNumber", "Ctrl_recordedBy",
    "Ctrl_occurrenceStatus", "Ctrl_eventDate", "Ctrl_year", "Ctrl_month", "Ctrl_day",
    "Ctrl_habitat", "Ctrl_fieldNotes", "Ctrl_eventRemarks", "Ctrl_countryCode",
    "Ctrl_stateProvince", "Ctrl_municipality", "Ctrl_county", "Ctrl_locality",
    "Ctrl_level0Name", "Ctrl_level1Name", "Ctrl_level2Name", 
     "Ctrl_level3Name",
    "Ctrl_identifiedBy", "Ctrl_dateIdentified", "Ctrl_scientificName", "Ctrl_taxonRank",
    "Ctrl_decimalLatitude", "Ctrl_decimalLongitude", "Ctrl_nameRecordedBy_Standard",
    "Ctrl_recordNumber_Standard", "Ctrl_key_family_recordedBy_recordNumber",
    "Ctrl_geospatial_quality", "Ctrl_verbatim_quality", "Ctrl_moreInformativeRecord",
    "Ctrl_coordinates_validated_by_gbif_issue", "wcvp_plant_name_id", "wcvp_taxon_rank",
    "wcvp_taxon_status", "wcvp_family", "wcvp_taxon_name", "wcvp_taxon_authors", 
    
    "wcvp_reviewed", "wcvp_searchedName", "wcvp_searchNotes",
    "parseGBIF_digital_voucher", "parseGBIF_duplicates", "parseGBIF_num_duplicates",
    "parseGBIF_non_groupable_duplicates", "parseGBIF_duplicates_grouping_status",
    "parseGBIF_unidentified_sample", "parseGBIF_sample_taxon_name",
    "parseGBIF_sample_taxon_name_status", "parseGBIF_number_taxon_names",
    "parseGBIF_useful_for_spatial_analysis", "parseGBIF_decimalLatitude",
    "parseGBIF_decimalLongitude", "parseGBIF_wcvp_plant_name_id",
    "parseGBIF_wcvp_taxon_rank", 
     "parseGBIF_wcvp_taxon_status",
    "parseGBIF_wcvp_family", "parseGBIF_wcvp_taxon_name", "parseGBIF_wcvp_taxon_authors",
    "parseGBIF_wcvp_reviewed", "parseGBIF_dataset_result"),
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ\_digital\_voucher\_file}] CSV fila result of function select\_digital\_voucher()\$occ\_digital\_voucher

\item[\code{occ\_digital\_voucher}] data frame result of function select\_digital\_voucher()\$occ\_digital\_voucher

\item[\code{merge\_unusable\_data}] include records unique collection events incomplete in merge processing

\item[\code{fields\_to\_merge}] fields to merge

\item[\code{fields\_to\_compare}] fields to compare content frequency

\item[\code{fields\_to\_parse}] all fields

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Each data frame should be used as needed
\end{Details}
%
\begin{Value}
list with 10 data frames
\begin{itemize}

\item{} \strong{all\_data} All records processed, merged Unique collection events complete / incomplete and their duplicates
\item{} \strong{useable\_data\_merge} Merged Unique collection events complete
\item{} \strong{useable\_data\_raw} Raw Unique collection events complete
\item{} \strong{duplicates} Duplicates of unique collection events complete / incomplete
\item{} \strong{unusable\_data\_merge} Merged Unique collection events incomplete,
It is NA if merge\_unusable\_data is FALSE.
\item{} \strong{unusable\_data\_raw} Raw Unique collection events incomplete
\item{} \strong{parseGBIF\_general\_summary}
\item{} \strong{parseGBIF\_merge\_fields\_summary}
\item{} \strong{parseGBIF\_merge\_fields\_summary\_useable\_data}
\item{} \strong{parseGBIF\_merge\_fields\_summary\_unusable\_data} It is NA if merge\_unusable\_data is FALSE

\end{itemize}

\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{batch\_checkName\_wcvp}{batch.Rul.checkName.Rul.wcvp}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(export_data)

results <- export_data(occ_digital_voucher_file = file.occ_digital_voucher,
                       merge_unusable_data = TRUE)

names(results)

results$parseGBIF_general_summary
results$parseGBIF_merge_fields_summary
results$parseGBIF_merge_fields_summary_complete
NROW(results$all_data)
NROW(results$unique_collection_event_complete_merge)
NROW(results$unique_collection_event_incomplete_raw)
NROW(results$duplicates)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{extract\_gbif\_issue}{Extracting GBIF issues}{extract.Rul.gbif.Rul.issue}
%
\begin{Description}
Extract GBIF validation rules for occurrence records

GBIF recognises and documents several issues relating to the data fields for an individual record.
The issue field stores terms that represent an enumeration of GBIF validation rules.
Issues can lead to errors or unexpected data. The issues fields are therefore a valuable source of information
when assessing the quality of a record. In order to help GBIF and the data publishers improve the data,
GBIF flag records with various issues that they have encountered. These issues can be  used as filters applied
to occurrence searches. Not all issues indicate bad data, some flagthe fact that GBIF has altered values during
processing. The values of EnumOccurrenceIssue will be used by the function extract\_gbif\_issue as a model to tabulate
the GBIF issues of each record, individualizing them, in columns.TRUE or FALSE, flagging whether the issue applies or
not for each record.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
extract_gbif_issue(occ = NA, enumOccurrenceIssue = NA)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{enumOccurrenceIssue}] An enumeration of validation rules for single occurrence records by GBIF file, if NA, will be used, data(EnumOccurrenceIssue)
\end{ldescription}
\end{Arguments}
%
\begin{Details}
https://gbif.github.io/parsers/apidocs/org/gbif/api/vocabulary/OccurrenceIssue.html
\end{Details}
%
\begin{Value}
list with two data frames: summary, with the frequency of issues in the records
and occ\_gbif\_issue, with issues in columns with TRUE or FALSE for each record.
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{prepare\_gbif\_occurrence\_data}{prepare.Rul.gbif.Rul.occurrence.Rul.data}}, \code{\LinkA{select\_gbif\_fields}{select.Rul.gbif.Rul.fields}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}


library(ParsGBIF)

help(extract_gbif_issue)

occ_file <- 'https://raw.githubusercontent.com/pablopains/ParsGBIF/main/dataGBIF/Achatocarpaceae/occurrence.txt'

occ <- prepare_gbif_occurrence_data(gbif_occurrece_file = occ_file,
                                    columns = 'standard')

data(EnumOccurrenceIssue)

colnames(EnumOccurrenceIssue)

head(EnumOccurrenceIssue)

occ_gbif_issue <- extract_gbif_issue(occ = occ)

names(occ_gbif_issue)

head(occ_gbif_issue$summary)

colnames(occ_gbif_issue$occ_gbif_issue)

head(occ_gbif_issue$occ_gbif_issue)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{generate\_collection\_event\_key}{Generating the collection event key}{generate.Rul.collection.Rul.event.Rul.key}
%
\begin{Description}
This generates a key to identify the physical and digital duplicates, of a given collection event.
It combines the primary collector's surname, the collector's number and the botanical family, a key is created
(family + recordByStandardized + recordNumber\_Standard) that allows grouping the duplicates of the same unique
collection event.

It also identifiesnew collectors to be added to the collector dictionary and that can be reused in the future.

Include recordedByStandardized field with verified main collector's last name.
Include recordNumber\_Standard field with only numbers from recordNumber.
Create the collection event key to group duplicates in the key\_family\_recordedBy\_recordNumber field,
composed of the fields: family + recordedByStandardized + recordNumber\_Standard.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
generate_collection_event_key(
  occ = NA,
  collectorDictionary_checked_file = NA,
  collectorDictionary_checked = NA,
  collectorDictionary_file =
    "https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv",
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{collectorDictionary\_checked\_file}] Verified collector dictionary file - point to a file on your local disk (use file or data frame)

\item[\code{collectorDictionary\_checked}] Verified collector dictionary data frame (use file or data frame)

\item[\code{collectorDictionary\_file}] Collector dictionary file - point to a file on your local disk or upload via git at https://raw.githubusercontent.com/pablopains/parseGBIF/main/collectorDictionary/CollectorsDictionary.csv.

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Fields created for each incident record:
nameRecordedBy\_Standard,
recordNumber\_Standard,
key\_family\_recordedBy\_recordNumber,
key\_year\_recordedBy\_recordNumber
\end{Details}
%
\begin{Value}
list with three data frames:
occ\_collectorsDictionary, with update result fields only,
summary and
CollectorsDictionary\_add, with new collectors that can be added to the
collector dictionary that can be reused in the future.
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{collectors\_get\_name}{collectors.Rul.get.Rul.name}}, \code{\LinkA{prepare\_collectorsDictionary}{prepare.Rul.collectorsDictionary}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

collectorsDictionaryFromDataset <- prepare_lastNameRecordedBy(occ=occ,
                                                              collectorDictionary_checked_file='collectorDictionary_checked.csv')

names(collectorsDictionaryFromDataset)



\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{parseGBIF\_app}{parseGBIF App}{parseGBIF.Rul.app}
%
\begin{Description}
parseGBIF App
\end{Description}
%
\begin{Usage}
\begin{verbatim}
parseGBIF_app()
\end{verbatim}
\end{Usage}
%
\begin{Value}
CSV files
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{batch\_checkName\_wcvp}{batch.Rul.checkName.Rul.wcvp}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

parseGBIF_app()

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{parseGBIF\_summary}{Selecting the master digital voucher}{parseGBIF.Rul.summary}
%
\begin{Description}
...
\end{Description}
%
\begin{Usage}
\begin{verbatim}
parseGBIF_summary(
  parseGBIF_all_data = NA,
  file.parseGBIF_all_data = "",
  fields_to_merge = c("Ctrl_fieldNotes", "Ctrl_year", "Ctrl_stateProvince",
    "Ctrl_municipality", "Ctrl_locality", "Ctrl_countryCode", "Ctrl_eventDate",
    "Ctrl_habitat", "Ctrl_level0Name", "Ctrl_level1Name", "Ctrl_level2Name",
    "Ctrl_level3Name")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{parseGBIF\_all\_data}] ...

\item[\code{file.parseGBIF\_all\_data}] ...

\item[\code{fields\_to\_merge}] fields to merge

\item[\code{fields\_to\_compare}] fields to compare content frequency

\item[\code{fields\_to\_parse}] all fields

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
...
\end{Details}
%
\begin{Value}
\begin{itemize}

\item{} \strong{parseGBIF\_general\_summary}
\item{} \strong{parseGBIF\_merge\_fields\_summary}
\item{} \strong{parseGBIF\_merge\_fields\_summary\_useable\_data}
\item{} \strong{parseGBIF\_merge\_fields\_summary\_unusable\_data}

\end{itemize}

\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{batch\_checkName\_wcvp}{batch.Rul.checkName.Rul.wcvp}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}



results <- export_data_v2.1(occ_digital_voucher_file = '',
occ_digital_voucher = occ_digital$all_data,
merge_unusable_data = TRUE,
silence = FALSE)

names(results)

head(results$occ_all)
colnames(results$occ_all)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{prepare\_gbif\_occurrence\_data}{Preparing occurrence data downloaded from GBIF for use by parseGBIF}{prepare.Rul.gbif.Rul.occurrence.Rul.data}
%
\begin{Description}
Prepare occurrence data downloaded from GBIF to be used by ParsGBIF functions
\end{Description}
%
\begin{Usage}
\begin{verbatim}
prepare_gbif_occurrence_data(gbif_occurrece_file = "", columns = "standard")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{gbif\_occurrece\_file}] The name of the file from which the with occurrence data
downloaded from GBIF (by default "occurrence.txt")

\item[\code{columns}] Character vector of strings to indicate column names of the GBIF occurrence file.
Use 'standard' to select basic columns for use in the package, 'all' to select all available columns.
The default is 'standard'
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Select data fields and rename field names prefixed with "Ctrl\_"
\end{Details}
%
\begin{Value}
data.frame with renamed selected fields with prefix "Ctrl\_"
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{select\_gbif\_fields}{select.Rul.gbif.Rul.fields}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}


library(ParsGBIF)

help(prepare_gbif_occurrence_data)

occ_file <- 'https://raw.githubusercontent.com/pablopains/ParsGBIF/main/dataGBIF/Achatocarpaceae/occurrence.txt'

occ <- prepare_gbif_occurrence_data(gbif_occurrece_file = occ_file,
                                    columns = 'standard')

colnames(occ)

head(occ)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{select\_digital\_voucher}{Selecting the master digital voucher}{select.Rul.digital.Rul.voucher}
%
\begin{Description}
To group duplicates and choose the digital voucher:
Unique collection events can result in many ‘duplicate’ GBIF records. We designate one of these ‘duplicate’ records
as the master digital voucher, to which data from other duplicate vouchers can be merged (see export\_data):

\strong{Where the collection event key for grouping duplicates is complete}, then duplicates can be grouped / parsed.
To do so, we evaluate record completeness. Record completeness is calculated based on data-quality scores
for the information in the following  fields: recordedBy, recordNumber, year, institutionCode, catalogNumber, locality, municipality,
countryCode, stateProvince and fieldNotes. The spatial coordinates associated with each duplicate are ranked using a score for the
quality of the geospatial information. This score is calculated using the issues listed in the GBIF table, EnumOccurrenceIssue.
A score is calculated based on these issues (see above). The duplicate with the highest total score is assigned as the master voucher
for the unique collection event. Missing information contained in duplicate records of the unique collection event can then be merged
into the master digital voucher (see export\_data).

\strong{Where the collection event key is incomplete}, unique collection event duplicates cannot be parsed. In this case,
each record is considered as a unique collection event, without duplicates. However, to know the integrity
of the information, record completeness and quality of the geospatial information, are evaluated as described above.

\strong{How is the quality score calculated?}
parseGBIF\_digital\_voucher = The duplicate with the highest total score, sum of record completeness + quality of geospatial information.

\strong{How is record completeness calculated?}
The quality of the duplicate records associated with each collection event key is measured as the
completeness of a record, using the sum of a number of flags (see below) equal to TRUE.

\strong{Flags used to calculate record completeness}
\begin{itemize}

\item{} Is there information about the collector?
\item{} Is there information about the collection number?
\item{} Is there information about the year of collection?
\item{} Is there information about the institution code?
\item{} Is there information about the catalog number?
\item{} Is there information about the locality?
\item{} Is there information about the municipality of collection?
\item{} Is there information about the state/province of collection?
\item{} Is there information about the field notes?

\end{itemize}


\strong{The quality of geospatial information is based on geographic issues raised by GBIF.}
GIBF issues relating to geospatial data were classified into three classes based on the data quality
scores that we assigned to each of the following GBIF issues recorded in the EnumOccurrenceIssue.
\begin{itemize}

\item{} Issue does not affect coordinating accuracy, with selection\_score equal to -1
\item{} Issue has potential to affect coordinate accuracy, with selection\_score equal to -3
\item{} Records with a selection\_score equal to -9 are excluded.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
select_digital_voucher(
  occ = NA,
  occ_gbif_issue = NA,
  occ_wcvp_check_name = NA,
  occ_collectorsDictionary = NA,
  enumOccurrenceIssue = NA,
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{occ\_gbif\_issue}] = result of function extract\_gbif\_issue()\$occ\_gbif\_issue

\item[\code{occ\_wcvp\_check\_name}] = result of function batch\_checkName\_wcvp()\$occ\_wcvp\_check\_name

\item[\code{occ\_collectorsDictionary}] = result of function update\_collectorsDictionary()\$occ\_collectorsDictionary

\item[\code{enumOccurrenceIssue}] An enumeration of validation rules for single occurrence records by GBIF file, if NA, will be used, data(EnumOccurrenceIssue)

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
\begin{itemize}

\item{} parseGBIF\_duplicates\_grouping\_status - "groupable", "not groupable: no recordedBy and no recordNumber",
"not groupable: no recordNumber" or "not groupable: no recordedBy"
\item{} parseGBIF\_num\_duplicates number of duplicates records
\item{} parseGBIF\_duplicates TRUE/FALSE
\item{} parseGBIF\_non\_groupable\_duplicates TRUE/FALSE

\end{itemize}

\end{Details}
%
\begin{Value}
list with two data frames: occ\_digital voucher\_and:
occ\_digital\_voucher,  with all data processing fields and
occ\_results, only result fields.
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{batch\_checkName\_wcvp}{batch.Rul.checkName.Rul.wcvp}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(select_digital_voucher)

head(occ)
head(res_gbif_issue$occ_gbif_issue)
head(res_checkName_wcvp$occ_wcvp_check_name)
head(res_collectorsDictionary$occ_collectorsDictionary)
res_digital_voucher_and_sample_identification <- select_digital_voucher(occ = occ,
                                                                        occ_gbif_issue = res_gbif_issue$occ_gbif_issue,
                                                                        occ_wcvp_check_name = res_checkName_wcvp$occ_wcvp_check_name,
                                                                        occ_collectorsDictionary = res_collectorsDictionary$occ_collectorsDictionary,
                                                                        enumOccurrenceIssue = EnumOccurrenceIssue)

names(res_digital_voucher_and_sample_identification)

head(res_digital_voucher_and_sample_identification$occ_digital_voucher)
colnames(res_digital_voucher_and_sample_identification$occ_digital_voucher)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{select\_digital\_voucher\_v2.1}{Selecting the master digital voucher}{select.Rul.digital.Rul.voucher.Rul.v2.1}
%
\begin{Description}
To group duplicates and choose the digital voucher:
Unique collection events can result in many ‘duplicate’ GBIF records. We designate one of these ‘duplicate’ records
as the master digital voucher, to which data from other duplicate vouchers can be merged (see export\_data):

\strong{Where the collection event key for grouping duplicates is complete}, then duplicates can be grouped / parsed.
To do so, we evaluate record completeness. Record completeness is calculated based on data-quality scores
for the information in the following  fields: recordedBy, recordNumber, year, institutionCode, catalogNumber, locality, municipality,
countryCode, stateProvince and fieldNotes. The spatial coordinates associated with each duplicate are ranked using a score for the
quality of the geospatial information. This score is calculated using the issues listed in the GBIF table, EnumOccurrenceIssue.
A score is calculated based on these issues (see above). The duplicate with the highest total score is assigned as the master voucher
for the unique collection event. Missing information contained in duplicate records of the unique collection event can then be merged
into the master digital voucher (see export\_data).

\strong{Where the collection event key is incomplete}, unique collection event duplicates cannot be parsed. In this case,
each record is considered as a unique collection event, without duplicates. However, to know the integrity
of the information, record completeness and quality of the geospatial information, are evaluated as described above.

\strong{How is the quality score calculated?}
parseGBIF\_digital\_voucher = The duplicate with the highest total score, sum of record completeness + quality of geospatial information.

\strong{How is record completeness calculated?}
The quality of the duplicate records associated with each collection event key is measured as the
completeness of a record, using the sum of a number of flags (see below) equal to TRUE.

\strong{Flags used to calculate record completeness}
\begin{itemize}

\item{} Is there information about the collector?
\item{} Is there information about the collection number?
\item{} Is there information about the year of collection?
\item{} Is there information about the institution code?
\item{} Is there information about the catalog number?
\item{} Is there information about the locality?
\item{} Is there information about the municipality of collection?
\item{} Is there information about the state/province of collection?
\item{} Is there information about the field notes?

\end{itemize}


\strong{The quality of geospatial information is based on geographic issues raised by GBIF.}
GIBF issues relating to geospatial data were classified into three classes based on the data quality
scores that we assigned to each of the following GBIF issues recorded in the EnumOccurrenceIssue.
\begin{itemize}

\item{} Issue does not affect coordinating accuracy, with selection\_score equal to -1
\item{} Issue has potential to affect coordinate accuracy, with selection\_score equal to -3
\item{} Records with a selection\_score equal to -9 are excluded.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
select_digital_voucher_v2.1(
  occ = NA,
  occ_gbif_issue = NA,
  occ_wcvp_check_name = NA,
  occ_collectorsDictionary = NA,
  enumOccurrenceIssue = NA,
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{occ\_gbif\_issue}] = result of function extract\_gbif\_issue()\$occ\_gbif\_issue

\item[\code{occ\_wcvp\_check\_name}] = result of function batch\_checkName\_wcvp()\$occ\_wcvp\_check\_name

\item[\code{occ\_collectorsDictionary}] = result of function update\_collectorsDictionary()\$occ\_collectorsDictionary

\item[\code{enumOccurrenceIssue}] An enumeration of validation rules for single occurrence records by GBIF file, if NA, will be used, data(EnumOccurrenceIssue)

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
\begin{itemize}

\item{} parseGBIF\_duplicates\_grouping\_status - "groupable", "not groupable: no recordedBy and no recordNumber",
"not groupable: no recordNumber" or "not groupable: no recordedBy"
\item{} parseGBIF\_num\_duplicates number of duplicates records
\item{} parseGBIF\_duplicates TRUE/FALSE
\item{} parseGBIF\_non\_groupable\_duplicates TRUE/FALSE

\end{itemize}

\end{Details}
%
\begin{Value}
list with two data frames: occ\_digital voucher\_and:
occ\_digital\_voucher,  with all data processing fields and
occ\_results, only result fields.
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{batch\_checkName\_wcvp}{batch.Rul.checkName.Rul.wcvp}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(select_digital_voucher)

head(occ)
head(res_gbif_issue$occ_gbif_issue)
head(res_checkName_wcvp$occ_wcvp_check_name)
head(res_collectorsDictionary$occ_collectorsDictionary)
res_digital_voucher_and_sample_identification <- select_digital_voucher(occ = occ,
                                                                        occ_gbif_issue = res_gbif_issue$occ_gbif_issue,
                                                                        occ_wcvp_check_name = res_checkName_wcvp$occ_wcvp_check_name,
                                                                        occ_collectorsDictionary = res_collectorsDictionary$occ_collectorsDictionary,
                                                                        enumOccurrenceIssue = EnumOccurrenceIssue)

names(res_digital_voucher_and_sample_identification)

head(res_digital_voucher_and_sample_identification$occ_digital_voucher)
colnames(res_digital_voucher_and_sample_identification$occ_digital_voucher)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{select\_digital\_voucher\_v2.2}{Selecting the master digital voucher}{select.Rul.digital.Rul.voucher.Rul.v2.2}
%
\begin{Description}
To group duplicates and choose the digital voucher:
Unique collection events can result in many ‘duplicate’ GBIF records. We designate one of these ‘duplicate’ records
as the master digital voucher, to which data from other duplicate vouchers can be merged (see export\_data):

\strong{Where the collection event key for grouping duplicates is complete}, then duplicates can be grouped / parsed.
To do so, we evaluate record completeness. Record completeness is calculated based on data-quality scores
for the information in the following  fields: recordedBy, recordNumber, year, institutionCode, catalogNumber, locality, municipality,
countryCode, stateProvince and fieldNotes. The spatial coordinates associated with each duplicate are ranked using a score for the
quality of the geospatial information. This score is calculated using the issues listed in the GBIF table, EnumOccurrenceIssue.
A score is calculated based on these issues (see above). The duplicate with the highest total score is assigned as the master voucher
for the unique collection event. Missing information contained in duplicate records of the unique collection event can then be merged
into the master digital voucher (see export\_data).

\strong{Where the collection event key is incomplete}, unique collection event duplicates cannot be parsed. In this case,
each record is considered as a unique collection event, without duplicates. However, to know the integrity
of the information, record completeness and quality of the geospatial information, are evaluated as described above.

\strong{How is the quality score calculated?}
parseGBIF\_digital\_voucher = The duplicate with the highest total score, sum of record completeness + quality of geospatial information.

\strong{How is record completeness calculated?}
The quality of the duplicate records associated with each collection event key is measured as the
completeness of a record, using the sum of a number of flags (see below) equal to TRUE.

\strong{Flags used to calculate record completeness}
\begin{itemize}

\item{} Is there information about the collector?
\item{} Is there information about the collection number?
\item{} Is there information about the year of collection?
\item{} Is there information about the institution code?
\item{} Is there information about the catalog number?
\item{} Is there information about the locality?
\item{} Is there information about the municipality of collection?
\item{} Is there information about the state/province of collection?
\item{} Is there information about the field notes?

\end{itemize}


\strong{The quality of geospatial information is based on geographic issues raised by GBIF.}
GIBF issues relating to geospatial data were classified into three classes based on the data quality
scores that we assigned to each of the following GBIF issues recorded in the EnumOccurrenceIssue.
\begin{itemize}

\item{} Issue does not affect coordinating accuracy, with selection\_score equal to -1
\item{} Issue has potential to affect coordinate accuracy, with selection\_score equal to -3
\item{} Records with a selection\_score equal to -9 are excluded.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
select_digital_voucher_v2.2(
  occ = NA,
  occ_gbif_issue = NA,
  occ_wcvp_check_name = NA,
  occ_collectorsDictionary = NA,
  enumOccurrenceIssue = NA,
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{occ\_gbif\_issue}] = result of function extract\_gbif\_issue()\$occ\_gbif\_issue

\item[\code{occ\_wcvp\_check\_name}] = result of function batch\_checkName\_wcvp()\$occ\_wcvp\_check\_name

\item[\code{occ\_collectorsDictionary}] = result of function update\_collectorsDictionary()\$occ\_collectorsDictionary

\item[\code{enumOccurrenceIssue}] An enumeration of validation rules for single occurrence records by GBIF file, if NA, will be used, data(EnumOccurrenceIssue)

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
\begin{itemize}

\item{} parseGBIF\_duplicates\_grouping\_status - "groupable", "not groupable: no recordedBy and no recordNumber",
"not groupable: no recordNumber" or "not groupable: no recordedBy"
\item{} parseGBIF\_num\_duplicates number of duplicates records
\item{} parseGBIF\_duplicates TRUE/FALSE
\item{} parseGBIF\_non\_groupable\_duplicates TRUE/FALSE

\end{itemize}

\end{Details}
%
\begin{Value}
list with two data frames: occ\_digital voucher\_and:
occ\_digital\_voucher,  with all data processing fields and
occ\_results, only result fields.
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{batch\_checkName\_wcvp}{batch.Rul.checkName.Rul.wcvp}}, \code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

help(select_digital_voucher)

head(occ)
head(res_gbif_issue$occ_gbif_issue)
head(res_checkName_wcvp$occ_wcvp_check_name)
head(res_collectorsDictionary$occ_collectorsDictionary)
res_digital_voucher_and_sample_identification <- select_digital_voucher(occ = occ,
                                                                        occ_gbif_issue = res_gbif_issue$occ_gbif_issue,
                                                                        occ_wcvp_check_name = res_checkName_wcvp$occ_wcvp_check_name,
                                                                        occ_collectorsDictionary = res_collectorsDictionary$occ_collectorsDictionary,
                                                                        enumOccurrenceIssue = EnumOccurrenceIssue)

names(res_digital_voucher_and_sample_identification)

head(res_digital_voucher_and_sample_identification$occ_digital_voucher)
colnames(res_digital_voucher_and_sample_identification$occ_digital_voucher)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{select\_gbif\_fields}{select\_gbif\_fields}{select.Rul.gbif.Rul.fields}
%
\begin{Description}
Select columns in GBIF occurrence data
\end{Description}
%
\begin{Usage}
\begin{verbatim}
select_gbif_fields(columns = "standard")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{columns}] 'standard' basic columns about what, when, where, and who collected, 'all' all available columns or list column names
\end{ldescription}
\end{Arguments}
%
\begin{Details}
"standard" : indicated by \strong{(standard)}

or

'all':
\begin{itemize}

\item{} 'gbifID' \strong{(standard)}
\item{} 'abstract'
\item{} 'accessRights'
\item{} 'accrualMethod'
\item{} 'accrualPeriodicity'
\item{} 'accrualPolicy'
\item{} 'alternative'
\item{} 'audience'
\item{} 'available'
\item{} 'bibliographicCitation' \strong{(standard)}
\item{} 'conformsTo'
\item{} 'contributor'
\item{} 'coverage'
\item{} 'created'
\item{} 'creator'
\item{} 'date'
\item{} 'dateAccepted'
\item{} 'dateCopyrighted'
\item{} 'dateSubmitted'
\item{} 'description'
\item{} 'educationLevel'
\item{} 'extent'
\item{} 'format'
\item{} 'hasFormat'
\item{} 'hasPart'
\item{} 'hasVersion'
\item{} 'identifier'
\item{} 'instructionalMethod'
\item{} 'isFormatOf'
\item{} 'isPartOf'
\item{} 'isReferencedBy'
\item{} 'isReplacedBy'
\item{} 'isRequiredBy'
\item{} 'isVersionOf'
\item{} 'issued'
\item{} 'language' \strong{(standard)}
\item{} 'license'
\item{} 'mediator'
\item{} 'medium'
\item{} 'modified'
\item{} 'provenance'
\item{} 'publisher'
\item{} 'references'
\item{} 'relation'
\item{} 'replaces'
\item{} 'requires'
\item{} 'rights'
\item{} 'rightsHolder'
\item{} 'source'
\item{} 'spatial'
\item{} 'subject'
\item{} 'tableOfContents'
\item{} 'temporal'
\item{} 'title'
\item{} 'type'
\item{} 'valid'
\item{} 'institutionID'
\item{} 'collectionID'
\item{} 'datasetID'
\item{} 'institutionCode' \strong{(standard)}
\item{} 'collectionCode' \strong{(standard)}
\item{} 'datasetName' \strong{(standard)}
\item{} 'ownerInstitutionCode'
\item{} 'basisOfRecord' \strong{(standard)}
\item{} 'informationWithheld' \strong{(standard)}
\item{} 'dataGeneralizations' \strong{(standard)}
\item{} 'dynamicProperties'
\item{} 'occurrenceID' \strong{(standard)} \# occ\_search(occurrenceId='BRA:UNEMAT:HPAN:6089')
\item{} 'catalogNumber' \strong{(standard)}
\item{} 'recordNumber' \strong{(standard)}
\item{} 'recordedBy' \strong{(standard)}
\item{} 'recordedByID'
\item{} 'individualCount'
\item{} 'organismQuantity'
\item{} 'organismQuantityType'
\item{} 'sex'
\item{} 'lifeStage'
\item{} 'reproductiveCondition'
\item{} 'behavior'
\item{} 'establishmentMeans'
\item{} 'degreeOfEstablishment'
\item{} 'pathway'
\item{} 'georeferenceVerificationStatus' \strong{(standard)}
\item{} 'occurrenceStatus' \strong{(standard)}
\item{} 'preparations'
\item{} 'disposition'
\item{} 'associatedOccurrences'
\item{} 'associatedReferences'
\item{} 'associatedSequences'
\item{} 'associatedTaxa'
\item{} 'otherCatalogNumbers'
\item{} 'occurrenceRemarks'
\item{} 'organismID'
\item{} 'organismName'
\item{} 'organismScope'
\item{} 'associatedOrganisms'
\item{} 'previousIdentifications'
\item{} 'organismRemarks'
\item{} 'materialSampleID'
\item{} 'eventID'
\item{} 'parentEventID'
\item{} 'fieldNumber'
\item{} 'eventDate' \strong{(standard)}
\item{} 'eventTime'
\item{} 'startDayOfYear'
\item{} 'endDayOfYear'
\item{} 'year' \strong{(standard)}
\item{} 'month' \strong{(standard)}
\item{} 'day' \strong{(standard)}
\item{} 'verbatimEventDate'
\item{} 'habitat' \strong{(standard)}
\item{} 'samplingProtocol'
\item{} 'sampleSizeValue'
\item{} 'sampleSizeUnit'
\item{} 'samplingEffort'
\item{} 'fieldNotes' \strong{(standard)}
\item{} 'eventRemarks' \strong{(standard)}
\item{} 'locationID'   \strong{(standard)}
\item{} 'higherGeographyID'
\item{} 'higherGeography' \strong{(standard)}
\item{} 'continent'
\item{} 'waterBody'
\item{} 'islandGroup' \strong{(standard)}
\item{} 'island' \strong{(standard)}
\item{} 'countryCode' \strong{(standard)}
\item{} 'stateProvince' \strong{(standard)}
\item{} 'county' \strong{(standard)}
\item{} 'municipality' \strong{(standard)}
\item{} 'locality' \strong{(standard)}
\item{} 'verbatimLocality' \strong{(standard)}
\item{} 'verbatimElevation'
\item{} 'verticalDatum'
\item{} 'verbatimDepth'
\item{} 'minimumDistanceAboveSurfaceInMeters'
\item{} 'maximumDistanceAboveSurfaceInMeters'
\item{} 'locationAccordingTo'
\item{} 'locationRemarks' \strong{(standard)}
\item{} 'decimalLatitude' \strong{(standard)}
\item{} 'decimalLongitude' \strong{(standard)}
\item{} 'coordinateUncertaintyInMeters'
\item{} 'coordinatePrecision'
\item{} 'pointRadiusSpatialFit'
\item{} 'verbatimCoordinateSystem' \strong{(standard)}
\item{} 'verbatimSRS'
\item{} 'footprintWKT'
\item{} 'footprintSRS'
\item{} 'footprintSpatialFit'
\item{} 'georeferencedBy'
\item{} 'georeferencedDate'
\item{} 'georeferenceProtocol'
\item{} 'georeferenceSources'
\item{} 'georeferenceRemarks'
\item{} 'geologicalContextID'
\item{} 'earliestEonOrLowestEonothem'
\item{} 'latestEonOrHighestEonothem'
\item{} 'earliestEraOrLowestErathem'
\item{} 'latestEraOrHighestErathem'
\item{} 'earliestPeriodOrLowestSystem'
\item{} 'latestPeriodOrHighestSystem'
\item{} 'earliestEpochOrLowestSeries'
\item{} 'latestEpochOrHighestSeries'
\item{} 'earliestAgeOrLowestStage'
\item{} 'latestAgeOrHighestStage'
\item{} 'lowestBiostratigraphicZone'
\item{} 'highestBiostratigraphicZone'
\item{} 'lithostratigraphicTerms'
\item{} 'group'
\item{} 'formation'
\item{} 'member'
\item{} 'bed'
\item{} 'identificationID'
\item{} 'verbatimIdentification' \strong{(standard)}
\item{} 'identificationQualifier' \strong{(standard)}
\item{} 'typeStatus' \strong{(standard)}
\item{} 'identifiedBy' \strong{(standard)}
\item{} 'identifiedByID'
\item{} 'dateIdentified' \strong{(standard)}
\item{} 'identificationReferences'
\item{} 'identificationVerificationStatus'
\item{} 'identificationRemarks'
\item{} 'taxonID'
\item{} 'scientificNameID'
\item{} 'acceptedNameUsageID'
\item{} 'parentNameUsageID'
\item{} 'originalNameUsageID'
\item{} 'nameAccordingToID'
\item{} 'namePublishedInID'
\item{} 'taxonConceptID'
\item{} 'scientificName' \strong{(standard)}
\item{} 'acceptedNameUsage'
\item{} 'parentNameUsage'
\item{} 'originalNameUsage'
\item{} 'nameAccordingTo'
\item{} 'namePublishedIn'
\item{} 'namePublishedInYear'
\item{} 'higherClassification'
\item{} 'kingdom'
\item{} 'phylum'
\item{} 'class'
\item{} 'order'
\item{} 'family' \strong{(standard)}
\item{} 'subfamily'
\item{} 'genus'
\item{} 'genericName'
\item{} 'subgenus'
\item{} 'infragenericEpithet'
\item{} 'specificEpithet'
\item{} 'infraspecificEpithet'
\item{} 'cultivarEpithet'
\item{} 'taxonRank' \strong{(standard)}
\item{} 'verbatimTaxonRank'
\item{} 'vernacularName'
\item{} 'nomenclaturalCode' \strong{(standard)}
\item{} 'taxonomicStatus' \strong{(standard)}
\item{} 'nomenclaturalStatus'
\item{} 'taxonRemarks'
\item{} 'datasetKey'
\item{} 'publishingCountry'
\item{} 'lastInterpreted'
\item{} 'elevation'
\item{} 'elevationAccuracy'
\item{} 'depth'
\item{} 'depthAccuracy'
\item{} 'distanceAboveSurface'
\item{} 'distanceAboveSurfaceAccuracy'
\item{} 'issue' \strong{(standard)}
\item{} 'mediaType' \strong{(standard)}
\item{} 'hasCoordinate' \strong{(standard)}
\item{} 'hasGeospatialIssues' \strong{(standard)}
\item{} 'taxonKey'
\item{} 'acceptedTaxonKey'
\item{} 'kingdomKey'
\item{} 'phylumKey'
\item{} 'classKey'
\item{} 'orderKey'
\item{} 'familyKey'
\item{} 'genusKey'
\item{} 'subgenusKey'
\item{} 'speciesKey'
\item{} 'species'
\item{} 'acceptedScientificName'
\item{} 'verbatimScientificName' \strong{(standard)}
\item{} 'typifiedName'
\item{} 'protocol'
\item{} 'lastParsed'
\item{} 'lastCrawled'
\item{} 'repatriated'
\item{} 'relativeOrganismQuantity'
\item{} 'level0Gid'
\item{} 'level0Name' \strong{(standard)}
\item{} 'level1Gid'
\item{} 'level1Name' \strong{(standard)}
\item{} 'level2Gid'
\item{} 'level2Name' \strong{(standard)}
\item{} 'level3Gid'
\item{} 'level3Name' \strong{(standard)}
\item{} 'iucnRedListCategory'

\end{itemize}

\end{Details}
%
\begin{Value}
list of the columns names
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{extract\_gbif\_issue}{extract.Rul.gbif.Rul.issue}}, \code{\LinkA{prepare\_gbif\_occurrence\_data}{prepare.Rul.gbif.Rul.occurrence.Rul.data}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

# select_gbif_fields()

help(select_gbif_fields)

col_sel <- select_gbif_fields(columns = 'all')

col_sel <- select_gbif_fields(columns = 'standard')


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{standardize\_scientificName}{standardize\_scientificName}{standardize.Rul.scientificName}
%
\begin{Description}
standardize binomial name, variety, subspecies, form and hybrids, authorship
to allow comparison with names of taxa in the World Checklist of Vascular Plants (WCVP) database
\end{Description}
%
\begin{Usage}
\begin{verbatim}
standardize_scientificName(
  searchedName = "Alomia angustata (Gardner) Benth. ex Baker"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{searchedName}] scientific name, with or without author
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Standardize scientific name according to WCVP format.
Separate generic epithet, specific epithet, variety, subspecies, form, hybrid and author, in the scientific name, if any.
Standardize, according to WCVP, abbreviation of infrataxon, if any:
variety to var.,
subspecies to subsp.,
FORM to f.,
hybrid separator separate x from the specific epithet.
\end{Details}
%
\begin{Value}
searchedName,
standardizeName,
taxonAuthors,
taxonAuthors\_last
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{get\_wcvp}{get.Rul.wcvp}}, \code{\LinkA{checkName\_wcvp}{checkName.Rul.wcvp}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

standardize_scientificName('Leucanthemum ×superbum (Bergmans ex J.W.Ingram) D.H.Kent')
standardize_scientificName('Alomia angustata (Gardner) Benth. ex Baker')
standardize_scientificName('Centaurea ×aemiliae Font Quer')


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{wcvp\_check\_name}{Check species names against World Checklist of Vascular Plants (WCVP) database}{wcvp.Rul.check.Rul.name}
%
\begin{Description}
Use the \Rhref{https://powo.science.kew.org//}{World Checklist of Vascular Plants WCVP}
\Rhref{http://sftp.kew.org/pub/data-repositories/WCVP/}{database} to check accepted names and update synonyms.

The World Checklist of Vascular Plants (WCVP) database is available from the
\Rhref{https://powo.science.kew.org/about-wcvp}{Royal Botanic Gardens, Kew}.
It can be downloaded to a folder of the user’s choice or into memory using the get\_wcvp function. The output has 33 columns.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
wcvp_check_name(
  searchedName = "Hemistylus brasiliensis Wedd.",
  wcvp_names = "",
  if_author_fails_try_without_combinations = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{searchedName}] scientific name, with or without author

\item[\code{wcvp\_names}] WCVP table, wcvp\_names.csv file from http://sftp.kew.org/pub/data-repositories/WCVP/ If NA, automatically load the latest version of the database by the function parseGBIF::wcvp\_get\_data(read\_only\_to\_memory = TRUE)\$wcvp\_names.

\item[\code{if\_author\_fails\_try\_without\_combinations}] option for partial verification of the authorship of the species. Remove the authors of combinations, in parentheses
\end{ldescription}
\end{Arguments}
%
\begin{Details}
About the World Checklist of Vascular Plants https://powo.science.kew.org/about-wcvp
searchNotes values:
\begin{itemize}

\item{} Accepted - When only one authorless scientific name is present in the list of TAXON\_name with
and TAXON\_STATUS equal to "Accepted",
verified\_speciesName = 100.
\item{} Accepted among homonyms - When more than one authorless scientific name is present in the
TAXON\_name list, but only one of the homonyms displays TAXON\_STATUS equal to "Accepted",
verified\_speciesName = number of matches/100.
\item{} Homonyms - When more than one authorless scientific name is present in the TAXON\_name list
and more than one, or none among the homonyms, display TAXON\_STATUS equal to "Accepted",
verified\_speciesName = number of matches/100.
Before searching for homonyms, there was a failure in trying to find the matching match between
authorless scientific name in TAXON\_name and author in TAXON\_AUTHORS, in these cases
verified\_author equal to 0 (zero),
\item{} Not Found: When the authorless scientific name is not present in the TAXON\_NAME LIST
\item{} Unplaced: o	When only one authorless scientific name is present in the list of TAXON\_name with and TAXON\_STATUS = "Unplaced"
\item{} Updated: When only one authorless scientific name is present in the list of TAXON\_name and ACCEPTED\_PLANT\_NAME\_ID
are not empty (and ACCEPTED\_PLANT\_NAME\_ID is different from the ID of the species consulted) taxon\_status\_of\_searchedName, plant\_name\_id\_of\_searchedName and taxon\_authors\_of\_searchedName values:
\begin{itemize}

\item{} When searchNotes equals "Updated" – The fields record the information of the scientific name originally consulted.
\item{} When searchNotes equals "Homonyms" - Fields record the information of homonymous synonyms separated by "|".

\end{itemize}

\item{} verified\_author values:
\begin{itemize}

\item{} When value equal to 100 – when there is matched match between authorless scientific name in TAXON\_name and author in TAXON\_AUTHORS.
\item{} When value equal to 50 – when there is combined correspondence between authorless scientific name in TAXON\_name and author, without (combination), in TAXON\_AUTHORS.
\item{} When value equal to 0 – regardless of the correspondence between authorless scientific name in TAXON\_name, author is not present in TAXON\_AUTHORS.

\end{itemize}


\end{itemize}

\end{Details}
%
\begin{Value}
Data frame with WCVP fields
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{wcvp\_check\_name\_batch}{wcvp.Rul.check.Rul.name.Rul.batch}}, \code{\LinkA{wcvp\_get\_data}{wcvp.Rul.get.Rul.data}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# These examples take >10 seconds to run and require 'parseGBIF::wcvp_get_data()'

library(parseGBIF)

help(wcvp_check_name)

wcvp_names <- wcvp_get_data(read_only_to_memory = TRUE)$wcvp_names

# 1) Updated
wcvp_check_name(searchedName = 'Hemistylus brasiliensis Wedd.',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# 2) Accepted
wcvp_check_name(searchedName = 'Hemistylus boehmerioides Wedd. ex Warm.',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# 3) Unplaced - taxon_status = Unplaced
wcvp_check_name(searchedName = 'Leucosyke australis Unruh',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# 4) Accepted among homonyms - When author is not informed. In this case, one of the homonyms, taxon_status is accepted
wcvp_check_name(searchedName = 'Parietaria cretica',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# When author is informed
wcvp_check_name(searchedName = 'Parietaria cretica L.',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# When author is informed
wcvp_check_name(searchedName = 'Parietaria cretica Moris',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# 5) Homonyms - When author is not informed. In this case, none of the homonyms, taxon_status is Accepted
wcvp_check_name(searchedName = 'Laportea peltata',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# When author is informed
wcvp_check_name(searchedName = 'Laportea peltata Gaudich. & Decne.',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)

# When author is informed
wcvp_check_name(searchedName = 'Laportea peltata (Blume) Gaudich.',
               wcvp_names = wcvp_names,
               if_author_fails_try_without_combinations = TRUE)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{wcvp\_check\_name\_batch}{In batch, use the WCVP database to check accepted names and update synonyms}{wcvp.Rul.check.Rul.name.Rul.batch}
%
\begin{Description}
Species’ names can be checked against WCVP database one by one, or in a batch mode.
To verify individual names, the function wcvp\_check\_name is used.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
wcvp_check_name_batch(
  occ = NA,
  wcvp_names = "",
  if_author_fails_try_without_combinations = TRUE,
  wcvp_selected_fields = "standard",
  silence = TRUE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{occ}] GBIF occurrence table with selected columns as select\_gbif\_fields(columns = 'standard')

\item[\code{wcvp\_names}] get data frame in parseGBIF::wcvp\_get\_data(read\_only\_to\_memory = TRUE)\$wcvp\_names
or configure function to save a copy on local disk to optimize loading, see details in help(wcvp\_get\_data)

\item[\code{if\_author\_fails\_try\_without\_combinations}] option for partial verification of the authorship of the species.
Remove the authors of combinations, in parentheses.

\item[\code{wcvp\_selected\_fields}] WCVP fields selected as return, 'standard' basic columns, 'all' all available columns.
The default is 'standard'

\item[\code{silence}] if TRUE does not display progress messages
\end{ldescription}
\end{Arguments}
%
\begin{Details}
See help(checkName\_wcvp)
\begin{itemize}

\item{} \Rhref{http://sftp.kew.org/pub/data-repositories/WCVP/}{about WCVP database}
\item{} \Rhref{https://powo.science.kew.org//}{World Checklist of Vascular Plants}
\item{} \Rhref{http://sftp.kew.org/pub/data-repositories/WCVP/}{WCVP database}
\item{} \Rhref{https://powo.science.kew.org/about-wcvp}{(about WCVP)}

\end{itemize}

\end{Details}
%
\begin{Value}
list with two data frames: summary, species list and occ\_wcvp\_check\_name, with WCVP fields
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{wcvp\_get\_data}{wcvp.Rul.get.Rul.data}}, \code{\LinkA{wcvp\_check\_name}{wcvp.Rul.check.Rul.name}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# These examples take >10 minutes to run and require 'parseGBIF::wcvp_get_data()'


library(parseGBIF)

help(wcvp_check_name_batch)

occ_file <- 'https://raw.githubusercontent.com/pablopains/parseGBIF/main/dataGBIF/Achatocarpaceae/occurrence.txt'

occ <- prepare_gbif_occurrence_data(gbif_occurrece_file = occ_file,
                                    columns = 'standard')

# wcvp_names <- wcvp_get_data(read_only_to_memory = TRUE)$wcvp_names
data(wcvp_names_Achatocarpaceae)

head(wcvp_names)

res_wcvp_check_name_batch <- wcvp_check_name_batch(occ = occ,
                                                 wcvp_names =  wcvp_names,
                                                 if_author_fails_try_without_combinations = TRUE,
                                                 wcvp_selected_fields = 'standard',
                                                 show_process = TRUE)

names(res_wcvp_check_name_batch)

head(res_wcvp_check_name_batch$summary)

head(res_wcvp_check_name_batch$occ_wcvp_check_name)



\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{wcvp\_get\_data}{Get WCVP database}{wcvp.Rul.get.Rul.data}
%
\begin{Description}
Download World Checklist of Vascular Plants (WCVP) database
\end{Description}
%
\begin{Usage}
\begin{verbatim}
wcvp_get_data(
  url_source = "http://sftp.kew.org/pub/data-repositories/WCVP/",
  read_only_to_memory = FALSE,
  path_results = "C:/parseGBIF",
  update = FALSE,
  load_distribution = FALSE,
  load_rda_data = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{url\_source}] http://sftp.kew.org/pub/data-repositories/WCVP/

\item[\code{read\_only\_to\_memory}] TRUE to in-memory read-only, not writing a copy to local disk

\item[\code{path\_results}] download destination folder, if read\_only\_to\_memory FALSE

\item[\code{update}] TRUE to update and load files, FALSE to keep local version and load files, if read\_only\_to\_memory FALSE

\item[\code{load\_distribution}] TRUE to load file with geographical distribution of species, if read\_only\_to\_memory FALSE

\item[\code{load\_rda\_data}] Load the WCVP name database from the rda file distributed with the package. To ensure updates, it is recommended to reinstall the package frequently.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
http://sftp.kew.org/pub/data-repositories/WCVP/ This is the public SFTP (Secure File Transfer Protocol) site of the Royal Botanic Gardens, Kew. This space contains data resources publicly accessible to the user `anonymous'.  No password required for access. Use of data made available via this site may be subject to legal and licensing restrictions. The README in the top-level directory for each data resource provides specific information about its terms of use.
\end{Details}
%
\begin{Value}
list with two data frames: wcvp\_names and wcvp\_distribution
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{wcvp\_check\_name}{wcvp.Rul.check.Rul.name}}, \code{\LinkA{wcvp\_check\_name\_batch}{wcvp.Rul.check.Rul.name.Rul.batch}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

# load package
library(parseGBIF)

help(wcvp_get_data)

# Download wcvp database to local disk
path_data <- tempdir() # you can change this folder

wcvp <- wcvp_get_data(url_source = 'http://sftp.kew.org/pub/data-repositories/WCVP/',
                 read_only_to_memory = FALSE,
                 path_results = path_data,
                 update = FALSE,
                 load_distribution = TRUE)

names(wcvp)

head(wcvp$wcvp_names)
colnames(wcvp$wcvp_names)

head(wcvp$wcvp_distribution)
colnames(wcvp$wcvp_distribution)


\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{wcvp\_get\_data\_v2.1}{Get WCVP database}{wcvp.Rul.get.Rul.data.Rul.v2.1}
%
\begin{Description}
Download World Checklist of Vascular Plants (WCVP) database
\end{Description}
%
\begin{Usage}
\begin{verbatim}
wcvp_get_data_v2.1(
  url_source = "http://sftp.kew.org/pub/data-repositories/WCVP/",
  read_only_to_memory = FALSE,
  path_results = "C:/parseGBIF",
  update = FALSE,
  load_distribution = FALSE,
  load_rda_data = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{url\_source}] http://sftp.kew.org/pub/data-repositories/WCVP/

\item[\code{read\_only\_to\_memory}] TRUE to in-memory read-only, not writing a copy to local disk

\item[\code{path\_results}] download destination folder, if read\_only\_to\_memory FALSE

\item[\code{update}] TRUE to update and load files, FALSE to keep local version and load files, if read\_only\_to\_memory FALSE

\item[\code{load\_distribution}] TRUE to load file with geographical distribution of species, if read\_only\_to\_memory FALSE

\item[\code{load\_rda\_data}] Load the WCVP name database from the rda file distributed with the package. To ensure updates, it is recommended to reinstall the package frequently.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
http://sftp.kew.org/pub/data-repositories/WCVP/ This is the public SFTP (Secure File Transfer Protocol) site of the Royal Botanic Gardens, Kew. This space contains data resources publicly accessible to the user `anonymous'.  No password required for access. Use of data made available via this site may be subject to legal and licensing restrictions. The README in the top-level directory for each data resource provides specific information about its terms of use.
\end{Details}
%
\begin{Value}
list with two data frames: wcvp\_names and wcvp\_distribution
\end{Value}
%
\begin{Author}
Pablo Hendrigo Alves de Melo,
Nadia Bystriakova \&
Alexandre Monro
\end{Author}
%
\begin{SeeAlso}
\code{\LinkA{wcvp\_check\_name}{wcvp.Rul.check.Rul.name}}, \code{\LinkA{wcvp\_check\_name\_batch}{wcvp.Rul.check.Rul.name.Rul.batch}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

# load package
library(parseGBIF)

help(wcvp_get_data)

# Download wcvp database to local disk
path_data <- tempdir() # you can change this folder

wcvp <- wcvp_get_data(url_source = 'http://sftp.kew.org/pub/data-repositories/WCVP/',
                 read_only_to_memory = FALSE,
                 path_results = path_data,
                 update = FALSE,
                 load_distribution = TRUE)

names(wcvp)

head(wcvp$wcvp_names)
colnames(wcvp$wcvp_names)

head(wcvp$wcvp_distribution)
colnames(wcvp$wcvp_distribution)


\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
