---
title: "parseGBIF Manual"

author:
  - Pablo Hendrigo Alves de Melo^[Instituto Federal de Educação, Ciência e Tecnologia de Minas Gerais, pablopains@yahoo.com.br]
  - Nadia Bystriakova^[Natural History Museum, London, n_bystriakova@yahoo.com]
  - Alexandre Monro^[Royal Botanic Gardens, Kew, a.monro@kew.org]
  
date: "`r Sys.Date()`"
  
output: word_document

template: template.tex
---

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

# parseGBIF Manual


parseGBIF package is designed to convert [Global Biodiversity Information Facility - GBIF](https://www.gbif.org/) species occurrence data to a more comprehensible format to be used for further analysis, e.g. spatial. The package provides tools for verifying and standardizing species scientific names and for selecting the most informative species records when duplicates are available. The Manual provides a brief introduction to parseGBIF, with more information available from Help pages accessed via help(function_name).

## Installation

You can install the development version of parseGBIF from [GitHub](https://github.com/pablopains/parseGBIF).
To install parseGBIF, run 

```{r example_install, eval=FALSE}
devtools::install_github("pablopains/parseGBIF")
```

Please site parseGBIF as:
```{r example_citation, eval=TRUE}
print(citation("parseGBIF"), bibtex = FALSE)
```

## Example
__parseGBIF makes it easy to get species occurrence records based on GBIF.__

### 1. GBIF data preparation
#### 1.1. Obtaining occurrence data of the species records from GBIF
  1.1.1. Access a registered account in [GBIF](gbif.org) 
  
  1.1.2. Filter occurrences using available fields, for instance:
  
  * Basis of record: _Preserved specimen_
  * Occurrence status: _present_
  * Scientific name: _Botanical family name_ (e.g. Achatocarpaceae) or __filter by other fields__

  1.1.3. Request to download information in __DARWIN CORE ARCHIVE FORMAT__
  
  1.1.4. Download compressed file and unzip downloaded file
  
  1.1.5. Use the __occurrence.txt__ file as input to the prepare_gbif_occurrence_data(gbif_occurrece_file = 'occurrence.txt') function
  
#### 1.2. Preparing occurrence data downloaded from GBIF 

To prepare occurrence data downloaded from GBIF to be used by parseGBIF functions, run prepare_gbif_occurrence_data.

```{r example_prepare_gbif_occurrence_data, eval=TRUE, message=FALSE, warning=FALSE}
  library(parseGBIF)
  
  occ_file <- 'https://raw.githubusercontent.com/pablopains/parseGBIF/main/dataGBIF/Achatocarpaceae/occurrence.txt'
  
  occ <- parseGBIF::prepare_gbif_occurrence_data(gbif_occurrece_file = occ_file, columns = 'standard')
  
  head(occ)
```

When parsing data, the user can choose between “standard” and “all” columns to be selected. The “standard” format has 54 data fields (columns), and the “all” format, 257 data fields (columns).

```{r example_select_gbif_fields, eval=TRUE, message=FALSE, warning=FALSE}
  col_standard <- parseGBIF::select_gbif_fields(columns = 'standard')
  
  str(col_standard)

  col_all <- parseGBIF::select_gbif_fields(columns = 'all')

  str(col_all)
```


#### 1.3. Extracting GBIF issue 

There are many things that can go wrong and we continously encounter unexpected data.
In order to help us and publishers improve the data, we flag records with various issues
that we have encountered. This is also very useful for data consumers as you can include
these issues as filters in occurrence searches. Not all issues indicate bad data.
Some are merley flagging the fact that GBIF has altered values during processing.
On the details page of any occurrence record you will see the list of issues in the notice at the bottom.

```{r aaa, eval=TRUE, message=FALSE, warning=FALSE}
  data(EnumOccurrenceIssue)

  colnames(EnumOccurrenceIssue)
  
  help(EnumOccurrenceIssue)
  print(?parseGBIF::EnumOccurrenceIssue)
```


```{r example_extract_gbif_issue, eval=TRUE, message=FALSE, warning=FALSE}

 occ_gbif_issue <- parseGBIF::extract_gbif_issue(occ = occ)

 names(occ_gbif_issue)

 head(occ_gbif_issue$summary)
```

### 2. Check species names against WCVP database

The World Checklist of Vascular Plants (WCVP) database is available from the (Royal Botanic Gardens, Kew) [https://powo.science.kew.org/about-wcvp]. It can be downloaded to a folder of the user’s choice or into memory using get_wcvp function. The output has 33 columns.

```{r example_wcvp_names, eval=TRUE, message=FALSE, warning=FALSE}
  data(wcvp_names_Achatocarpaceae)
  wcvp_names <- wcvp_names_Achatocarpaceae
  
  # wcvp_names <- wcvp_get_data(read_only_to_memory = TRUE)$wcvp_names
  
  colnames(wcvp_names)
```

Species’ names can be checked against WCVP database one by one or in a batch mode. To verify individual names, the function wcvp_check_name is used.

```{r example_wcvp_check_name, eval=TRUE, message=FALSE, warning=FALSE}
  name.checked <- wcvp_check_name(searchedName = 'Achatocarpus mollis H.Walter',
                 wcvp_names = wcvp_names,
                 if_author_fails_try_without_combinations = TRUE)
  name.checked[,c(3:5,22,23,40)]
```

To check names in a batch mode, there is wcvp_check_name_batch function. It uses the occurrence data (occ) and WCVP names list (wcvp_names) generated in the previous steps.

```{r example_wcvp_check_name_batch, eval=TRUE, message=FALSE, warning=FALSE}
  names.checked <- wcvp_check_name_batch(occ = occ,
                                                   wcvp_names =  wcvp_names,
                                                   if_author_fails_try_without_combinations = TRUE,
                                                   wcvp_selected_fields = 'standard')
  
  names(names.checked)
  
  head(names.checked$summary)
```

To bring species’ names into line with the format used by WCVP, the function standardize_scientificName inserts space between the hybrid separator (x) and specific epithet, and also standardizes abbreviations of infrataxa (variety, subspecies, form).

```{r example_standardize_scientificName, eval=TRUE, message=FALSE, warning=FALSE}
# hybrid separator
standardize_scientificName('Leucanthemum ×superbum (Bergmans ex J.W.Ingram) D.H.Kent')

# variety 
standardize_scientificName('Platymiscium pubescens subsp. fragrans (Rusby) Klitg.')

# subspecies

```

The funtion get_lastNameRecordedB returns the last name of the main collector in recordedBy field.

```{r example_collectors_get_name, eval=TRUE, message=FALSE, warning=FALSE}
# library(parseGBIF)
collectors_get_name('Melo, P.H.A, Bystriakova, N. & Monro, A.')

collectors_get_name('Monro, A.; Bystriakova, N. & Melo, P.H.A')

collectors_get_name('Bystriakova, N., Monro, A.,Melo, P.H.A')

```


### 3. Collectors Dictionary

To extract the last name of the main collector based on the recordedBy field and assemble a list relating the last name of the main collector and the raw data from the recordedBy, use the collectors_prepare_dictionary function. It uses the occurrence data (occ) generated in the previous step.

#### 3.1 Prepare dictionary collectors

```{r example_collectors_prepare_dictionary, eval=TRUE, message=FALSE, warning=FALSE}

collectorsDictionary.dataset <- collectors_prepare_dictionary(occ = occ)

head(collectorsDictionary.dataset)
```

#### 3.2 Check the main collector's last name
It is recommended to check the main collector's last name in the nameRecordedBy_Standard field. The goal is to standardize the main collector's last name, which was automatically extracted from the recordedBy field, standardized in uppercase and with non-ascii characters replaced, so that a botanical collector is always recognized by the same last name.

If the searched recordedBy exists in the collector's dictionary, the function retrieves the last name of the main collector referring to the recordedBy (in this case the CollectorDictionary field will be indicated with 'checked'), otherwise, it returns the last name of the main collector, extracted automatically from the recordedBy field .

Once verified, the collector's dictionary can be reused in the future.

```{r example_check_collectorsDictionary, eval=TRUE, message=FALSE, warning=FALSE}

  file.collectorsDictionary.dataset <-  'file_collectorsDictionary_dataset.csv'

  write.csv(collectorsDictionary.dataset,
            file.collectorsDictionary.dataset, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")
```


#### 3.3 Update dictionary collectors

Create a key to group duplicates of a sample.

It also returns new collectors to be added to the collector dictionary that can be reused in the future.


```{r example_collectors_update_dictionary, eval=TRUE, message=FALSE, warning=FALSE}

  occ_collectorsDictionary <- collectors_update_dictionary(occ=occ,
                                        collectorDictionary_checked_file = file.collectorsDictionary.dataset)

  names(occ_collectorsDictionary)
  
  head(occ_collectorsDictionary$occ_collectorsDictionary[,c(1,3)])

```


 
### 4. Select digital voucher

To group duplicates and choose the digital voucher:

1) If the key for grouping duplicates is complete with collector information and collection number, sample duplicates can be grouped. In this case, the voucher with the highest score is selected among the duplicates in the sample.

2) If the key to group duplicates is incomplete, sample duplicates cannot be grouped due to missing collector information and/or collection number. In this case, each record is considered a sample, without duplicates, and a voucher is selected for each sample.

#### How is the information score calculated? 

moreInformativeRecord = sum of **textual quality** + **quality of geospatial information**.  

#### How is the **quality of textual** information calculated?

##### The **Text quality** is the sum of the number of flags with text quality equal to TRUE.  

Is there information about the collector?  
Is there information about the collection number?  
Is there information about the year of collection?  
Is there information about the institution code?  
Is there information about the catalog number?  
Is there information about the locality?  
Is there information about the municipality of collection?  
Is there information about the state/province of collection?  
Is there information about the bibliographic citation?  

#### How is the **quality of geospatial information** calculated?

##### The **quality of geospatial information** is based on geographic issues made available by GBIF.

GIBF issues on the quality of geospatial information were classified into three levels.

* Not applicable, with selection_score equal to 0
* Does not affect coordinating accuracy, with selection_score equal to -1
* Potentially affect coordinate accuracy, with selection_score equal to -3
* Records to be excluded from spatial analysis, with selection_score equal to -9

#### How is the taxonomic identification of the sample chosen?

1) When the key to group the duplicates is complete:

The accepted TAXON_NAME identified at or below the specified level and the most frequent among the duplicates is chosen.

In case of a tie in frequency, in alphabetical order, the first accepted TAXON_NAME identified up to or below the specific level is chosen.

If there is no identification, equal to or less than the specific level, for the sample, the sample is indicated as unidentified.

2) When the key to group the duplicates is incomplete:

If so, the accepted TAXON_NAME identified at or below the specified level is used. If there is no identification, equal to or less than the specific level, the sample is indicated as unidentified.


```{r example_select_digital_voucher, eval=TRUE, message=FALSE, warning=FALSE}

occ_digital_voucher <- parseGBIF::select_digital_voucher(occ = occ,
                                                         occ_gbif_issue = occ_gbif_issue$occ_gbif_issue,
                                                         occ_wcvp_check_name = names.checked$occ_wcvp_check_name ,
                                                         occ_collectorsDictionary = occ_collectorsDictionary$occ_collectorsDictionary)

  names(occ_digital_voucher)
  
  colnames(occ_digital_voucher$occ_digital_voucher)
    
  file.occ_digital_voucher <-  'occ_digital_voucher.csv'

  write.csv(occ_digital_voucher$occ_join_results,
            file.occ_digital_voucher, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")
```

### 5. Export of results

From the selected digital voucher:
  * select the taxonomic identification of the sample,
  * Select geographic coordinates,
  * Merge information between fields of duplicates of a sample,
  * Compare the frequency of content in fields
  * Generate data summary
  * Export results

```{r example_export, eval=TRUE, message=FALSE, warning=FALSE}

occ_results <- export_data(occ_digital_voucher_file = file.occ_digital_voucher)
  
names(occ_results)

NROW(occ_results$occ_all)
NROW(occ_results$occ_in_merge)
NROW(occ_results$occ_in_raw)
# NROW(occ_results$occ_out_to_recover_merge)
NROW(occ_results$occ_out_to_recover_raw)
NROW(occ_results$occ_dup)

occ_results$summary

  file.all <- 'parseGBIF_occ_all.csv'
  write.csv(occ_results$occ_all,
            file.all, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")

  file.summary <- 'parseGBIF_summary.csv'
  write.csv(occ_results$summary,
            file.summary, 
            row.names = FALSE, 
            fileEncoding = "UTF-8", 
            na = "")

```
